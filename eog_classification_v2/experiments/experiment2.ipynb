{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "<br>\n",
    "-- ViT Base model hyperparameters explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 13:02:12.240122: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-04 13:02:12.814127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-02-04 13:02:12.814174: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-02-04 13:02:12.814180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/donghyun/eye_writing_classification/v2_dataset/200_points_dataset/'\n",
    "\n",
    "with open(data_path + 'eog_katakana_200.json') as f:\n",
    "  eog_katakana = json.load(f)\n",
    "\n",
    "with open(data_path + 'eog_raw_numbers_200.json') as f:\n",
    "  eog_raw_numbers = json.load(f)\n",
    "\n",
    "with open(data_path + 'reference_data_200.json') as f:\n",
    "  reference_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "vit_hidden_size = [128,256,512]\n",
    "vit_patch_size = [5,10]\n",
    "vit_heads = [4,8]\n",
    "vit_n_layers = [8,12]\n",
    "vit_mlp_units = [[128,64],\n",
    "                 [64,32]]\n",
    "vit_dropout = [0]\n",
    "vit_mlp_dropout = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config class\n",
    "\n",
    "class Config:\n",
    "    split_ratio = 0.3\n",
    "    ref_key = 'numbers'\n",
    "    batch_size = 10            # fix : must be equaled with number of test pairs\n",
    "    n_batch = 180\n",
    "    lr = 0.0005\n",
    "    model_type = 'ViTBaseModel'\n",
    "    ViT_params = {}\n",
    "    epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for hyperparameters\n",
    "\n",
    "cols = ['hidden_size', 'batch_size', 'patch_size', 'heads', 'n_layers', 'mlp_units', 'dropout', 'mlp_dropout', 'score']\n",
    "best_perform_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "raw_numbers_dict = defaultdict(list)\n",
    "\n",
    "i = 0\n",
    "for hs, ps, heads, n_layers, mlp_units, dropout, mlp_dropout in product(vit_hidden_size,\n",
    "                                                                            vit_patch_size,\n",
    "                                                                            vit_heads,\n",
    "                                                                            vit_n_layers,\n",
    "                                                                            vit_mlp_units,\n",
    "                                                                            vit_dropout,\n",
    "                                                                            vit_mlp_dropout\n",
    "                                                                            ):\n",
    "    i+=1\n",
    "    print('index : ', i)\n",
    "\n",
    "    cfg = Config\n",
    "    cfg.ViT_params['hidden_size'] = hs\n",
    "    cfg.ViT_params['batch_size'] = cfg.batch_size\n",
    "    cfg.ViT_params['patch_size'] = ps\n",
    "    cfg.ViT_params['heads'] = heads\n",
    "    cfg.ViT_params['n_layers'] = n_layers\n",
    "    cfg.ViT_params['mlp_units'] = mlp_units\n",
    "    cfg.ViT_params['dropout'] = dropout\n",
    "    cfg.ViT_params['mlp_dropout'] = mlp_dropout\n",
    "\n",
    "    _, _, _, test_acc_list = utils.experiment(cfg, eog_raw_numbers, reference_data)\n",
    "    score = np.mean(test_acc_list[-3:])\n",
    "\n",
    "    best_perform_df.loc[i] = [hs, cfg.batch_size, ps, heads, n_layers, str(mlp_units), dropout, mlp_dropout, score]\n",
    "\n",
    "best_perform_df = best_perform_df.sort_values(by='score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters save\n",
    "\n",
    "save_path = '/home/donghyun/eye_writing_classification/experiments/save/'\n",
    "best_perform_df.to_csv(save_path+'experiment2_vit_hyperparams.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>heads</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>mlp_units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>mlp_dropout</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[64, 32]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>[64, 32]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>[128, 64]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[128, 64]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[64, 32]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[128, 64]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>[64, 32]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[64, 32]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>512</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[128, 64]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[128, 64]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  hidden_size  batch_size  patch_size  heads  \\\n",
       "0             0          14          128          10          10      8   \n",
       "1             1           8          128          10           5      8   \n",
       "2             2          15          128          10          10      8   \n",
       "3             3           1          128          10           5      4   \n",
       "4             4           6          128          10           5      8   \n",
       "5             5          13          128          10          10      8   \n",
       "6             6          16          128          10          10      8   \n",
       "7             7           2          128          10           5      4   \n",
       "8             8          41          512          10          10      4   \n",
       "9             9           9          128          10          10      4   \n",
       "\n",
       "   n_layers  mlp_units  dropout  mlp_dropout      score  \n",
       "0         8   [64, 32]        0            0  90.416667  \n",
       "1        12   [64, 32]        0            0  90.000000  \n",
       "2        12  [128, 64]        0            0  89.583333  \n",
       "3         8  [128, 64]        0            0  88.958333  \n",
       "4         8   [64, 32]        0            0  87.500000  \n",
       "5         8  [128, 64]        0            0  87.083333  \n",
       "6        12   [64, 32]        0            0  87.083333  \n",
       "7         8   [64, 32]        0            0  86.875000  \n",
       "8         8  [128, 64]        0            0  86.875000  \n",
       "9         8  [128, 64]        0            0  86.875000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the hyperparameters\n",
    "\n",
    "save_path = '/home/donghyun/eye_writing_classification/experiments/save/'\n",
    "best_perform_df = pd.read_csv(save_path+'experiment2_vit_hyperparams.csv')\n",
    "\n",
    "best_perform_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Num_config:\n",
    "    split_ratio = 0.3\n",
    "    ref_key = 'numbers'\n",
    "    batch_size = 10            # fix : Not must be equaled with number of test pairs \n",
    "    n_batch = 50\n",
    "    lr = 0.0005\n",
    "    model_type = 'ViTBaseModel'\n",
    "    ViT_params = {}\n",
    "    epochs = 100\n",
    "\n",
    "class Kata_config:\n",
    "    split_ratio = 0.3\n",
    "    ref_key = 'katakana'\n",
    "    batch_size = 12            # fix : Not must be equaled with number of test pairs \n",
    "    n_batch = 50\n",
    "    lr = 0.001\n",
    "    model_type = 'ViTBaseModel'\n",
    "    ViT_params = {}\n",
    "    epochs = 100\n",
    "\n",
    "best_params = best_perform_df.iloc[0].to_dict()\n",
    "best_params['mlp_units'] = re.sub('[\\[\\]]','',best_params['mlp_units'])\n",
    "best_params['mlp_units'] = list(map(int,best_params['mlp_units'].split(',')))       # str to list\n",
    "\n",
    "num_cfg = Num_config\n",
    "num_cfg.ViT_params = best_params.copy()\n",
    "num_cfg.ViT_params['batch_size'] = num_cfg.batch_size\n",
    "\n",
    "kata_cfg = Kata_config\n",
    "kata_cfg.ViT_params = best_params.copy()\n",
    "kata_cfg.ViT_params['batch_size'] = kata_cfg.batch_size\n",
    "\n",
    "times = 10\n",
    "numbers_dict = defaultdict(list)\n",
    "katakana_dict = defaultdict(list)\n",
    "num_cm = np.zeros((num_cfg.batch_size,num_cfg.batch_size))\n",
    "kata_cm = np.zeros((kata_cfg.batch_size,kata_cfg.batch_size))\n",
    "for t in range(times):\n",
    "    _, num_train_acc, num_train_loss, num_test_acc, num_confusion_matrix = utils.experiment(num_cfg, eog_raw_numbers, reference_data)\n",
    "    _, kat_train_acc, kat_train_loss, kat_test_acc, kata_confusion_matrix = utils.experiment(kata_cfg, eog_katakana, reference_data)\n",
    "    numbers_dict[t] = [num_train_acc, num_train_loss, num_test_acc]\n",
    "    katakana_dict[t] = [kat_train_acc, kat_train_loss, kat_test_acc]\n",
    "    num_cm += num_confusion_matrix\n",
    "    kata_cm += kata_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = np.sum(num_confusion_matrix, axis=1)\n",
    "kata_total = np.sum(kata_confusion_matrix, axis=1)\n",
    "norm_num_cm = num_confusion_matrix / num_total\n",
    "norm_kata_cm = kata_confusion_matrix / kata_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ticks = ['num 0', 'num 1', 'num 2', 'num 3', 'num 4',\n",
    "             'num 5', 'num 6', 'num 7', 'num 8', 'num 9']\n",
    "\n",
    "df_cm = pd.DataFrame(norm_num_cm, index=num_ticks, columns=num_ticks)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.title('Arabic numbers confusion matrix')\n",
    "cm = sns.heatmap(df_cm, annot=True)\n",
    "cm.set_yticklabels(cm.get_yticklabels(), rotation=45)\n",
    "cm.set_xticklabels(cm.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kata_ticks = ['kata 1', 'kata 2', 'kata 3', 'kata 4', 'kata 5', 'kata 6',\n",
    "              'kata 7', 'kata 8', 'kata 9', 'kata 10', 'kata 11', 'kata 12']\n",
    "\n",
    "df_cm = pd.DataFrame(norm_num_cm, index=kata_ticks, columns=kata_ticks)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.title('katakana gesture confusion matrix')\n",
    "cm = sns.heatmap(df_cm, annot=True)\n",
    "cm.set_yticklabels(cm.get_yticklabels(), rotation=45)\n",
    "cm.set_xticklabels(cm.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/donghyun/eye_writing_classification/experiments/save/'\n",
    "\n",
    "with open(save_path + 'ex2_katakana_results.json', 'w') as f:\n",
    "    json.dump(dict(katakana_dict),f)\n",
    "\n",
    "with open(save_path + 'ex2_numbers_results.json', 'w') as f:\n",
    "    json.dump(dict(numbers_dict),f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/donghyun/eye_writing_classification/experiments/save/'\n",
    "\n",
    "with open(save_path+'ex1_raw_numbers_results.json') as f:\n",
    "    hybrid_raw_numbers_results = json.load(f)\n",
    "\n",
    "with open(save_path+'ex2_numbers_results.json') as f:\n",
    "    vit_numbers_results = json.load(f)\n",
    "\n",
    "with open(save_path+'ex2_katakana_results.json') as f:\n",
    "    vit_katakana_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_test_acc = []\n",
    "vit_test_acc = []\n",
    "for t in range(10):\n",
    "    key = str(t)\n",
    "    hybrid_test_acc.append(hybrid_raw_numbers_results[key][2])\n",
    "    vit_test_acc.append(vit_numbers_results[key][2])\n",
    "\n",
    "hybrid_avg_results = np.array(hybrid_test_acc).mean(axis=0)\n",
    "vit_avg_results  =np.array(vit_test_acc).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(data_list):\n",
    "    return np.mean(data_list), max(data_list), min(data_list), np.std(data_list)\n",
    "\n",
    "hybrid_numbers_test_performance = [t[-1] for t in hybrid_test_acc]\n",
    "vit_numbers_test_performance = [t[-1] for t in vit_test_acc]\n",
    "\n",
    "print('Accuracy base on raw numbers with 10 repetitions')\n",
    "print(' '*29 +'1,     2,    3,      4,      5,      6,     7,     8,     9,     10,       Avg.   Best.   Worst.  Std.')\n",
    "print('hybrid model performance : {}, {}'.format(hybrid_numbers_test_performance, analysis(hybrid_numbers_test_performance)))\n",
    "print('ViT model performance    : {}, {}'.format(vit_numbers_test_performance, analysis(vit_numbers_test_performance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize = (20,8))\n",
    "\n",
    "# test accuracy\n",
    "axes[0].plot(hybrid_avg_results, c = 'b', linestyle = 'solid', linewidth = 3)\n",
    "axes[0].plot(vit_avg_results, c = 'r', linestyle = 'solid', linewidth = 3)\n",
    "\n",
    "axes[0].set_ylim(20,100)\n",
    "\n",
    "axes[0].set_title(\"Evaluation\", fontsize=20)\n",
    "axes[0].set_xlabel('Epoch', fontsize = 20)\n",
    "axes[0].set_ylabel('Accuracy', fontsize = 20)\n",
    "\n",
    "axes[0].legend(['Hybrid base model', 'ViT base model'], fontsize = 15)\n",
    "\n",
    "# plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('eog')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db961e0436efeabab578e79efd22f04ed4082e196e7e1c09c24525d7c028a5aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
